{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Project, I am using the reviews Dataset provided by Zomato to recommend similar restaurants. I am using `TF-IDF` to process the reviews of customers. The model recommends on the basis of cosine similarity between two reviews and ranks them on the basis of restaurant rating.\n",
    "\n",
    "These are the major components to this project:\n",
    "\n",
    "* removing unneccessary columns and cleaning the columns to make it uniform across all rows\n",
    "* removing punctuation, stopwords from reviews column and vectorizing it using `TF-IDF`\n",
    "* calculating the cosine similarities between the reviews, and outputting restaurants in descending order of cosine similarities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1.1` Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fgNqJ386OswO"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1.2` Reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wSaNeR1XOswV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reading the data in chunks to prevent memory issues\n",
    "# dataset size is 500 MB\n",
    "mylist = []\n",
    "\n",
    "for chunk in  pd.read_csv('zomato.csv', chunksize=2000):\n",
    "    mylist.append(chunk)\n",
    "\n",
    "zomato_real = pd.concat(mylist, axis= 0)\n",
    "del mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1.3` Cleaning the columns and removing unnecessary ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OaN8Nzx8OswX"
   },
   "outputs": [],
   "source": [
    "# dropping columns which are not significant\n",
    "zomato=zomato_real.drop(['url','dish_liked','phone'],axis=1)\n",
    "\n",
    "# dropping duplicates\n",
    "zomato.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove missing values\n",
    "zomato.dropna(inplace=True)\n",
    "\n",
    "# renaming columns\n",
    "zomato = zomato.rename(columns={'approx_cost(for two people)':'cost','listed_in(type)':'type', 'listed_in(city)':'city'})\n",
    "\n",
    "# basic preprocessing\n",
    "zomato['cost'] = zomato['cost'].astype(str) \n",
    "zomato['cost'] = zomato['cost'].apply(lambda x: x.replace(',','.')) #cleaning cost column\n",
    "zomato['cost'] = zomato['cost'].astype(float) #converting type to float\n",
    "\n",
    "# removing reviews for hotel which dont have a rating or is new\n",
    "zomato = zomato.loc[zomato.rate !='NEW']\n",
    "zomato = zomato.loc[zomato.rate !='-'].reset_index(drop=True)\n",
    "\n",
    "# removing /5 from every rating \n",
    "remove_slash = lambda x: x.replace('/5','') \n",
    "zomato.rate = zomato.rate.apply(remove_slash).str.strip().astype('float')\n",
    "\n",
    "# standardising the name of restaurants by making first letter of each word capital and others small\n",
    "zomato.name = zomato.name.apply(lambda x:x.title())\n",
    "\n",
    "# making online order column boolean\n",
    "zomato.online_order = zomato.online_order.replace('Yes',True)\n",
    "zomato.online_order = zomato.online_order.replace('No',False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1.4` Feature scaling and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the mean rating a a restaurant from all its reviews and forming a new column\n",
    "restaurants = list(zomato['name'].unique())\n",
    "zomato['mean_ratings'] = 0\n",
    "for i in range(len(restaurants)):\n",
    "    zomato['mean_ratings'][zomato['name']==restaurants[i]] = zomato['rate'][zomato['name']==restaurants[i]].mean()\n",
    "    \n",
    "    \n",
    "# scaling the mean ratings column between 1-5 to have uniform range of values which gives a better idea of its actual rating\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(1,5))\n",
    "zomato[['mean_ratings']] = scaler.fit_transform(zomato[['mean_ratings']]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `2.` Tokenizing the reviews column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the column and using TFIDF to tokenize the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `2.1` Cleaning the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARD38xojOswd"
   },
   "outputs": [],
   "source": [
    "# the reviews column is being processed\n",
    "\n",
    "zomato[\"reviews_list\"] = zomato[\"reviews_list\"].str.lower()\n",
    "\n",
    "import string\n",
    "punc_to_remove = string.punctuation\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \n",
    "    '''\n",
    "    removing punctuation from reviews\n",
    "    '''\n",
    "    return text.translate(str.maketrans('','',punc_to_remove))\n",
    "\n",
    "zomato['reviews_list'] = zomato['reviews_list'].apply(remove_punctuation)\n",
    "\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \n",
    "    '''\n",
    "    removing stopwords which don't add much meaning to a sentence . Stopwords include a, and, the..\n",
    "    '''\n",
    "    return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
    "\n",
    "zomato['reviews_list'] = zomato['reviews_list'].apply(remove_stopwords)\n",
    "\n",
    "def remove_urls(text):\n",
    "    '''\n",
    "    removing the urls from reviews\n",
    "    '''\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "zomato['reviews_list'] = zomato['reviews_list'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCgHkYXdOswf"
   },
   "outputs": [],
   "source": [
    "# restaurant_names = list(zomato['name'].unique())\n",
    "# def get_top_words(column, top_nu_of_words, nu_of_word):\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     '''\n",
    "#     vec = CountVectorizer(ngram_range= nu_of_word, stop_words='english')\n",
    "#     bag_of_words = vec.fit_transform(column)\n",
    "#     sum_words = bag_of_words.sum(axis=0)\n",
    "#     words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "#     words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "#     return words_freq[:top_nu_of_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `2.2` Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iG9cxtAeOswf"
   },
   "outputs": [],
   "source": [
    "#dropping columns which will not be used\n",
    "zomato=zomato.drop(['address','rest_type', 'type', 'menu_item', 'votes'],axis=1)\n",
    "\n",
    "#shuffling the dataset\n",
    "df_percent = zomato.sample(frac=1)\n",
    "\n",
    "#setting name column as index\n",
    "df_percent.set_index('name', inplace=True)\n",
    "\n",
    "#this is a series of names of restaurants\n",
    "indices = pd.Series(df_percent.index)\n",
    "\n",
    "#using TF_IDF to vectorize the reviews list column\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,1), stop_words='english', min_df=0)\n",
    "tfidf_matrix = tfidf.fit_transform(df_percent['reviews_list'])\n",
    "\n",
    "# calculating the cosine similarities between all the reviews\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3` Recommendation based on cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7BzsNW9Oswh"
   },
   "outputs": [],
   "source": [
    "def recommend(name, cosine_similarities = cosine_similarities):\n",
    "    \n",
    "    '''\n",
    "        for every restaurant name, it takes the cosine similarities of its reviews \n",
    "        to all the other reviews, ranks them in descending order,and outputs the\n",
    "        restaurant names corresponding to them\n",
    "        \n",
    "        input : restaurant for which you want reviews\n",
    "        output : dataframe with restaurants name and its details\n",
    "    '''\n",
    "    \n",
    "    recommend_restaurant = []\n",
    "    \n",
    "    \n",
    "    idx = indices[indices == name].index[0] #first index where name matches \n",
    "    \n",
    "    \n",
    "    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending=False) # taking the cosine similarities of that review and sorting in descending\n",
    "    \n",
    "   \n",
    "    top30_indexes = list(score_series.iloc[0:31].index) #taking top 30 indices\n",
    "    \n",
    "   \n",
    "    for each in top30_indexes:\n",
    "        recommend_restaurant.append(list(df_percent.index)[each]) #taking names corresponding to those top 30 reviews\n",
    "    \n",
    " \n",
    "    df_new = pd.DataFrame(columns=['cuisines', 'mean_ratings', 'cost','location'])\n",
    "    \n",
    "    # taking out the (cuisines','mean_ratings', 'cost','location') for that particular name and dropping duplicates, and then sorting by mean ratings\n",
    "    for each in recommend_restaurant:\n",
    "        df_new = df_new.append(pd.DataFrame(df_percent[['cuisines','mean_ratings', 'cost','location']][df_percent.index == each].sample()))\n",
    "    \n",
    "    \n",
    "    df_new = df_new.drop_duplicates(subset=['cuisines','mean_ratings', 'cost','location'], keep=False)\n",
    "    df_new = df_new.sort_values(by='mean_ratings', ascending=False)\n",
    "    \n",
    "    print('TOP %s RESTAURANTS LIKE %s WITH SIMILAR REVIEWS: ' % (str(len(df_new)), name))\n",
    "    \n",
    "    return df_new"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Restaurant Recommender System.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
